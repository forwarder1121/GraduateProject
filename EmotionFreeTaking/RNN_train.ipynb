{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qtH6JNAa_YOS"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import os\n",
        "# CUDA 장치 설정 (특정 GPU 사용)\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.multiprocessing as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import DataLoader\n",
        "import importlib \n",
        "\n",
        "\n",
        "# 다중 프로세싱 시작 방식 설정 (DataLoader 사용 시)\n",
        "try:\n",
        "    mp.set_start_method('spawn', force=True)\n",
        "except RuntimeError:\n",
        "    print(\"Multiprocessing start method already set. Please restart the runtime.\")\n",
        "\n",
        "# 사용자 정의 모듈 임포트 (기존 임포트된 모듈 제거 및 새로 임포트)\n",
        "try:\n",
        "    # 세션에 저장된 모듈 제거\n",
        "    if \"models\" in sys.modules:\n",
        "        importlib.reload(sys.modules[\"models\"])\n",
        "    if \"Segdataset\" in sys.modules:\n",
        "        importlib.reload(sys.modules[\"Segdataset\"])\n",
        "    if \"utils\" in sys.modules:\n",
        "        importlib.reload(sys.modules[\"utils\"])\n",
        "\n",
        "    # 사용자 정의 모듈 임포트\n",
        "    from models import *\n",
        "    from Segdataset import SegDataset, load_mfcc_and_labels  # 데이터셋 클래스 및 파일 읽기 함수 가져오기\n",
        "    from utils import plot_fold_performance  # 모델 성능 시각화 함수 가져오기\n",
        "\n",
        "except ImportError as e:\n",
        "    sys.exit(f\"Failed to import required modules: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JO5GJszBg-2y"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        # 데이터 경로 설정\n",
        "        self.data_root = '/workspace/dataset/free_talking_datasets/mfcc_split_voice_train'  # MFCC 파일이 저장된 루트 디렉토리\n",
        "        self.save_root = '/workspace/UndergraduateResearchAssistant/GraduateProject/code/EmotionFreeTaking/checkpoints/RNN'  # 모델 체크포인트를 저장할 경로\n",
        "\n",
        "        # 학습 설정\n",
        "        self.epoch = 100  # 학습 에포크 수\n",
        "        self.lr = 3e-4  # 학습률\n",
        "        self.batch_size = 32  # 배치 크기 배치 사이즈 16 -> 1600으로 상향 조절. 데이터 수 100배 넘게 되었으므로 ->350으로 축소 (gpu 메모리 부족)\n",
        "        self.num_workers = 2  # DataLoader에서 사용할 병렬 워커 수\n",
        "\n",
        "        # 랜덤 시드 및 특성 설정\n",
        "        self.random_seed = 1  # 재현 가능성을 위한 랜덤 시드\n",
        "        self.n_mfcc = 16  # MFCC 특성 차원 수\n",
        "\n",
        "        # K-Fold 교차 검증 설정\n",
        "        self.n_splits = 5  # 교차 검증을 위한 K-fold 개수\n",
        "\n",
        "        # 모델 설정 (CNN, RNN, Transformer 중 선택)\n",
        "        self.model_type = 'RNN'  # 사용할 모델 타입 ('CNN', 'RNN', 'Transformer' 중 하나)\n",
        "\n",
        "# 설정 인스턴스 생성\n",
        "opt = Args()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (lstm): LSTM(16, 40, num_layers=4, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=160, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 모델 선택 및 초기화\n",
        "if opt.model_type == 'CNN':\n",
        "    model = CNN().to(device)\n",
        "elif opt.model_type == 'RNN':\n",
        "    model = RNN(n_mfcc=opt.n_mfcc).to(device)\n",
        "elif opt.model_type == 'Transformer':\n",
        "    model = Transformer(n_mfcc=opt.n_mfcc).to(device)\n",
        "else:\n",
        "    raise ValueError(f\"Invalid model type specified: {opt.model_type}\")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yqSs6MVMhEl0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading MFCC files: 100%|██████████| 263198/263198 [01:40<00:00, 2630.98file/s]\n"
          ]
        }
      ],
      "source": [
        "# MFCC 특징과 감정 레이블 로드\n",
        "mfcc_list, emotion_list = load_mfcc_and_labels(opt.data_root) # GPU에 데이터 적제 되어 있음\n",
        "\n",
        "# K-Fold 설정\n",
        "kf = KFold(n_splits=opt.n_splits, shuffle=True, random_state=opt.random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1/5\n",
            "Dataset loaded with 210558 samples.\n",
            "Dataset loaded with 52640 samples.\n",
            "Fold 1 | Epoch 0 | Train Loss: 1.0429519965014826 | Val Loss: 1.0433529991147004 | Val Accuracy: 0.24899316109422492\n",
            "Fold 1 | Epoch 1 | Train Loss: 1.0408680053590043 | Val Loss: 1.0427636548378547 | Val Accuracy: 0.24899316109422492\n",
            "Fold 1 | Epoch 2 | Train Loss: 1.0390313688446493 | Val Loss: 1.0415676421669842 | Val Accuracy: 0.24899316109422492\n",
            "Fold 1 | Epoch 3 | Train Loss: 1.0375322809895586 | Val Loss: 1.0392678380737188 | Val Accuracy: 0.24899316109422492\n",
            "Fold 1 | Epoch 4 | Train Loss: 1.0357922594549809 | Val Loss: 1.0384141807860516 | Val Accuracy: 0.24899316109422492\n",
            "Fold 1 | Epoch 5 | Train Loss: 1.0338457137332677 | Val Loss: 1.036622391681903 | Val Accuracy: 0.24899316109422492\n",
            "Fold 1 | Epoch 6 | Train Loss: 1.0328560032676393 | Val Loss: 1.0353227181275202 | Val Accuracy: 0.24899316109422492\n",
            "Fold 1 | Epoch 7 | Train Loss: 1.0311396511279807 | Val Loss: 1.0363988935766248 | Val Accuracy: 0.24899316109422492\n",
            "Fold 1 | Epoch 8 | Train Loss: 1.0334080158078682 | Val Loss: 1.0344966745304118 | Val Accuracy: 0.24899316109422492\n"
          ]
        }
      ],
      "source": [
        "# 학습 및 검증 루프 시작\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(mfcc_list)):\n",
        "    print(f\"Fold {fold + 1}/{opt.n_splits}\")\n",
        "\n",
        "    # 모델 초기화\n",
        "    if opt.model_type == 'CNN':\n",
        "        model = CNN().to(device)\n",
        "    elif opt.model_type == 'RNN':\n",
        "        model = RNN(n_mfcc=opt.n_mfcc).to(device)\n",
        "    elif opt.model_type == 'Transformer':\n",
        "        model = Transformer(n_mfcc=opt.n_mfcc).to(device)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid model type: {opt.model_type}\")\n",
        "    \n",
        "\n",
        "    # 학습/검증 데이터로 쪼개기\n",
        "    train_mfcc = [mfcc_list[i] for i in train_idx]\n",
        "    train_emotion = [emotion_list[i] for i in train_idx]\n",
        "    val_mfcc = [mfcc_list[i] for i in val_idx]\n",
        "    val_emotion = [emotion_list[i] for i in val_idx]\n",
        "\n",
        "    train_set = SegDataset(train_mfcc, train_emotion)\n",
        "    val_set = SegDataset(val_mfcc, val_emotion)\n",
        "\n",
        "    # 데이터 로더 생성 (각 배치 단위로 데이터를 GPU에 올리기)\n",
        "    train_loader = DataLoader(train_set, batch_size=opt.batch_size, shuffle=True, drop_last=True, num_workers=opt.num_workers)\n",
        "    val_loader = DataLoader(val_set, batch_size=opt.batch_size, shuffle=False, drop_last=True, num_workers=opt.num_workers)\n",
        "\n",
        "    # 각 fold에 따라 pos_weight 동적으로 설정\n",
        "    num_pos = sum(em == 1 for em in train_emotion)\n",
        "    num_neg = sum(em == 0 for em in train_emotion)\n",
        "    pos_weight = torch.tensor([num_neg / num_pos]).to(device) if num_pos > 0 else torch.tensor([1.0]).to(device)\n",
        "\n",
        "    # 손실 함수 및 옵티마이저 선언\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=opt.lr)\n",
        "\n",
        "    # 현재 폴드 값들 저장\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_epoch = 0\n",
        "\n",
        "    # 에포크 루프\n",
        "    for epo in range(opt.epoch):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        # 학습 루프 (각 배치 단위로 데이터를 GPU에 올리기)\n",
        "        for mfcc, emotion in train_loader:\n",
        "            # 데이터를 GPU로 옮기기\n",
        "            mfcc, emotion = mfcc.to(device), emotion.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output_emotion = model(mfcc)\n",
        "\n",
        "            emotion = emotion.float()\n",
        "            loss = criterion(output_emotion[:, 0].squeeze(), emotion)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # 사용 후 메모리에서 해제\n",
        "            del mfcc, emotion, output_emotion\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # 검증 루프\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct_emotion = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for mfcc, emotion in val_loader:\n",
        "                # 데이터를 GPU로 옮기기\n",
        "                mfcc, emotion = mfcc.to(device), emotion.to(device)\n",
        "                output_emotion = model(mfcc)\n",
        "                emotion = emotion.float()\n",
        "\n",
        "                loss = criterion(output_emotion[:, 0].squeeze(), emotion)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted_emotion = (torch.sigmoid(output_emotion[:, 0]) > 0.5).float()\n",
        "                correct_emotion += (predicted_emotion == emotion).sum().item()\n",
        "                total += emotion.size(0)\n",
        "\n",
        "                # 사용 후 메모리에서 해제\n",
        "                del mfcc, emotion, output_emotion\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        val_accuracy = correct_emotion / total\n",
        "        print(f\"Fold {fold + 1} | Epoch {epo} | Train Loss: {train_loss / len(train_loader)} | Val Loss: {val_loss / len(val_loader)} | Val Accuracy: {val_accuracy}\")\n",
        "\n",
        "        # 모델 저장\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_epoch = epo\n",
        "            torch.save(model.state_dict(), os.path.join(opt.save_root, f'fold_{fold + 1}_best_epoch.pth'))\n",
        "\n",
        "        # 학습 및 검증 손실 및 정확도 기록\n",
        "        train_losses.append(train_loss / len(train_loader))\n",
        "        val_losses.append(val_loss / len(val_loader))\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Fold {fold + 1} best epoch: {best_epoch}\")\n",
        "\n",
        "    # 각 폴드의 학습 손실, 검증 손실 및 정확도 시각화\n",
        "    plot_fold_performance(train_losses, val_losses, val_accuracies, fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 학습 및 검증 루프 시작\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(mfcc_list)):\n",
        "    print(f\"Fold {fold + 1}/{opt.n_splits}\")\n",
        "\n",
        "    # 모델 초기화\n",
        "    if opt.model_type == 'CNN':\n",
        "        model = CNN().to(device)\n",
        "    elif opt.model_type == 'RNN':\n",
        "        model = RNN(n_mfcc=opt.n_mfcc).to(device)\n",
        "    elif opt.model_type == 'Transformer':\n",
        "        model = Transformer(n_mfcc=opt.n_mfcc).to(device)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid model type: {opt.model_type}\")\n",
        "    \n",
        "\n",
        "    # 학습/검증 데이터로 쪼개기\n",
        "    train_mfcc = [mfcc_list[i] for i in train_idx]\n",
        "    train_emotion = [emotion_list[i] for i in train_idx]\n",
        "    val_mfcc = [mfcc_list[i] for i in val_idx]\n",
        "    val_emotion = [emotion_list[i] for i in val_idx]\n",
        "\n",
        "    train_set = SegDataset(train_mfcc, train_emotion)\n",
        "    val_set = SegDataset(val_mfcc, val_emotion)\n",
        "\n",
        "    # 데이터 로더 생성 (각 배치 단위로 데이터를 GPU에 올리기)\n",
        "    train_loader = DataLoader(train_set, batch_size=opt.batch_size, shuffle=True, drop_last=True, num_workers=opt.num_workers)\n",
        "    val_loader = DataLoader(val_set, batch_size=opt.batch_size, shuffle=False, drop_last=True, num_workers=opt.num_workers)\n",
        "\n",
        "    # 각 fold에 따라 pos_weight 동적으로 설정\n",
        "    num_pos = sum(em == 1 for em in train_emotion)\n",
        "    num_neg = sum(em == 0 for em in train_emotion)\n",
        "    pos_weight = torch.tensor([num_neg / num_pos]).to(device) if num_pos > 0 else torch.tensor([1.0]).to(device)\n",
        "\n",
        "    # 손실 함수 및 옵티마이저 선언\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=opt.lr)\n",
        "\n",
        "    # 현재 폴드 값들 저장\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_epoch = 0\n",
        "\n",
        "    # 에포크 루프\n",
        "    for epo in range(opt.epoch):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        # 학습 루프 (각 배치 단위로 데이터를 GPU에 올리기)\n",
        "        for mfcc, emotion in train_loader:\n",
        "            # 데이터를 GPU로 옮기기\n",
        "            mfcc, emotion = mfcc.to(device), emotion.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output_emotion = model(mfcc)\n",
        "\n",
        "            emotion = emotion.float()\n",
        "            loss = criterion(output_emotion[:, 0].squeeze(), emotion)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # 사용 후 메모리에서 해제\n",
        "            del mfcc, emotion, output_emotion\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # 검증 루프\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct_emotion = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for mfcc, emotion in val_loader:\n",
        "                # 데이터를 GPU로 옮기기\n",
        "                mfcc, emotion = mfcc.to(device), emotion.to(device)\n",
        "                output_emotion = model(mfcc)\n",
        "                emotion = emotion.float()\n",
        "\n",
        "                loss = criterion(output_emotion[:, 0].squeeze(), emotion)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted_emotion = (torch.sigmoid(output_emotion[:, 0]) > 0.56).float()\n",
        "                correct_emotion += (predicted_emotion == emotion).sum().item()\n",
        "                total += emotion.size(0)\n",
        "\n",
        "                # 사용 후 메모리에서 해제\n",
        "                del mfcc, emotion, output_emotion\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        val_accuracy = correct_emotion / total\n",
        "        print(f\"Fold {fold + 1} | Epoch {epo} | Train Loss: {train_loss / len(train_loader)} | Val Loss: {val_loss / len(val_loader)} | Val Accuracy: {val_accuracy}\")\n",
        "\n",
        "        # 모델 저장\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_epoch = epo\n",
        "            torch.save(model.state_dict(), os.path.join(opt.save_root, f'fold_{fold + 1}_best_epoch.pth'))\n",
        "\n",
        "        # 학습 및 검증 손실 및 정확도 기록\n",
        "        train_losses.append(train_loss / len(train_loader))\n",
        "        val_losses.append(val_loss / len(val_loader))\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Fold {fold + 1} best epoch: {best_epoch}\")\n",
        "\n",
        "    # 각 폴드의 학습 손실, 검증 손실 및 정확도 시각화\n",
        "    plot_fold_performance(train_losses, val_losses, val_accuracies, fold)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
