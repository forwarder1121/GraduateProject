{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qtH6JNAa_YOS"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'tb_frame'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m/workspace/UndergraduateResearchAssistant/GraduateProject/code/CREMA-D/CNN_train.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223131342e37302e32312e313130222c2275736572223a22726f6f74222c22706f7274223a31303030367d/workspace/UndergraduateResearchAssistant/GraduateProject/code/CREMA-D/CNN_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223131342e37302e32312e313130222c2275736572223a22726f6f74222c22706f7274223a31303030367d/workspace/UndergraduateResearchAssistant/GraduateProject/code/CREMA-D/CNN_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mSegdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m SegDataset, load_mfcc_and_labels,get_kfold_data  \u001b[39m# 데이터셋 클래스 및 파일 읽기 함수 가져오기\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223131342e37302e32312e313130222c2275736572223a22726f6f74222c22706f7274223a31303030367d/workspace/UndergraduateResearchAssistant/GraduateProject/code/CREMA-D/CNN_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_fold_performance,get_mfcc  \u001b[39m# 모델 성능 시각화 함수 가져오기\u001b[39;00m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_mfcc_and_labels' from 'Segdataset' (/workspace/UndergraduateResearchAssistant/GraduateProject/code/CREMA-D/Segdataset.py)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[1;32m/workspace/UndergraduateResearchAssistant/GraduateProject/code/CREMA-D/CNN_train.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223131342e37302e32312e313130222c2275736572223a22726f6f74222c22706f7274223a31303030367d/workspace/UndergraduateResearchAssistant/GraduateProject/code/CREMA-D/CNN_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223131342e37302e32312e313130222c2275736572223a22726f6f74222c22706f7274223a31303030367d/workspace/UndergraduateResearchAssistant/GraduateProject/code/CREMA-D/CNN_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     sys\u001b[39m.\u001b[39;49mexit(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mFailed to import required modules: \u001b[39;49m\u001b[39m{\u001b[39;49;00me\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
            "\u001b[0;31mSystemExit\u001b[0m: Failed to import required modules: cannot import name 'load_mfcc_and_labels' from 'Segdataset' (/workspace/UndergraduateResearchAssistant/GraduateProject/code/CREMA-D/Segdataset.py)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[0;32m/opt/conda/envs/tess/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2121\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[1;32m   2119\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2120\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[0;32m-> 2121\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[1;32m   2122\u001b[0m                                                      value))\n\u001b[1;32m   2123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2125\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcontains_exceptiongroup\u001b[39m(val):\n",
            "File \u001b[0;32m/opt/conda/envs/tess/lib/python3.9/site-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
            "File \u001b[0;32m/opt/conda/envs/tess/lib/python3.9/site-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m    569\u001b[0m             etype,\n\u001b[1;32m    570\u001b[0m             evalue,\n\u001b[1;32m    571\u001b[0m             (etb, chained_exc_ids),  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m             chained_exceptions_tb_offset,\n\u001b[1;32m    573\u001b[0m             context,\n\u001b[1;32m    574\u001b[0m         )\n\u001b[1;32m    575\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
            "File \u001b[0;32m/opt/conda/envs/tess/lib/python3.9/site-packages/IPython/core/ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m etb\n\u001b[0;32m-> 1435\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m   1436\u001b[0m     \u001b[39mself\u001b[39;49m, etype, evalue, etb, tb_offset, number_of_lines_of_context\n\u001b[1;32m   1437\u001b[0m )\n",
            "File \u001b[0;32m/opt/conda/envs/tess/lib/python3.9/site-packages/IPython/core/ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1323\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[1;32m   1324\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[1;32m   1325\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m   1327\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[1;32m   1328\u001b[0m     )\n\u001b[1;32m   1329\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1330\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
            "File \u001b[0;32m/opt/conda/envs/tess/lib/python3.9/site-packages/IPython/core/ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[1;32m   1165\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1166\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[1;32m   1171\u001b[0m ):\n\u001b[1;32m   1172\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m   1174\u001b[0m                                                            tb_offset)\n\u001b[1;32m   1176\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/envs/tess/lib/python3.9/site-packages/IPython/core/ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[1;32m   1061\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(\u001b[39mstr\u001b[39m(etype), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[1;32m   1062\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1063\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[1;32m   1064\u001b[0m )\n\u001b[1;32m   1066\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[1;32m   1067\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[0;32m/opt/conda/envs/tess/lib/python3.9/site-packages/IPython/core/ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[39mwhile\u001b[39;00m cf \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1130\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         mod \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetmodule(cf\u001b[39m.\u001b[39;49mtb_frame)\n\u001b[1;32m   1132\u001b[0m         \u001b[39mif\u001b[39;00m mod \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m             mod_name \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import os\n",
        "# CUDA 장치 설정 (특정 GPU 사용)\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.multiprocessing as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import DataLoader\n",
        "import importlib \n",
        "\n",
        "\n",
        "# 다중 프로세싱 시작 방식 설정 (DataLoader 사용 시)\n",
        "try:\n",
        "    mp.set_start_method('spawn', force=True)\n",
        "except RuntimeError:\n",
        "    print(\"Multiprocessing start method already set. Please restart the runtime.\")\n",
        "\n",
        "# 사용자 정의 모듈 임포트 (기존 임포트된 모듈 제거 및 새로 임포트)\n",
        "try:\n",
        "    # 세션에 저장된 모듈 제거\n",
        "    if \"models\" in sys.modules:\n",
        "        importlib.reload(sys.modules[\"models\"])\n",
        "    if \"Segdataset\" in sys.modules:\n",
        "        importlib.reload(sys.modules[\"Segdataset\"])\n",
        "    if \"utils\" in sys.modules:\n",
        "        importlib.reload(sys.modules[\"utils\"])\n",
        "\n",
        "    # 사용자 정의 모듈 임포트\n",
        "    from models import *\n",
        "    from Segdataset import SegDataset, load_mfcc_and_labels,get_kfold_data  # 데이터셋 클래스 및 파일 읽기 함수 가져오기\n",
        "    from utils import plot_fold_performance,get_mfcc  # 모델 성능 시각화 함수 가져오기\n",
        "\n",
        "except ImportError as e:\n",
        "    sys.exit(f\"Failed to import required modules: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO5GJszBg-2y"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        # 데이터 경로 설정\n",
        "        self.data_root = '/workspace/dataset/CREMA-D'\n",
        "        self.save_root = '/workspace/UndergraduateResearchAssistant/GraduateProject/code/CREMA-D/checkpoints'\n",
        "\n",
        "        # 학습 설정\n",
        "        self.epoch = 100  # 학습 에포크 수\n",
        "        self.lr = 5e-4  # 학습률\n",
        "        self.batch_size = 128 # 배치 크기 배치 사이즈 16 -> 1600으로 상향 조절. 데이터 수 100배 넘게 되었으므로 ->350으로 축소 (gpu 메모리 부족)\n",
        "        self.num_workers = 2  # DataLoader에서 사용할 병렬 워커 수\n",
        "\n",
        "        # 랜덤 시드 및 특성 설정\n",
        "        self.random_seed = 1  # 재현 가능성을 위한 랜덤 시드\n",
        "        self.n_mfcc = 20  # MFCC 특성 차원 수\n",
        "\n",
        "        # K-Fold 교차 검증 설정\n",
        "        self.n_splits = 5  # 교차 검증을 위한 K-fold 개수\n",
        "\n",
        "        # 모델 설정 (CNN, RNN, Transformer 중 선택)\n",
        "        self.model_type = 'CNN'  # 사용할 모델 타입 ('CNN', 'RNN', 'Transformer' 중 하나)\n",
        "\n",
        "# 설정 인스턴스 생성\n",
        "opt = Args()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (cnn): Sequential(\n",
            "    (0): Conv1d(126, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU()\n",
            "    (9): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (10): AdaptiveAvgPool1d(output_size=1)\n",
            "  )\n",
            "  (fc1): Linear(in_features=256, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 모델 선택 및 초기화\n",
        "if opt.model_type == 'CNN':\n",
        "    model = CNN().to(device)\n",
        "elif opt.model_type == 'RNN':\n",
        "    model = RNN(n_mfcc=opt.n_mfcc).to(device)\n",
        "elif opt.model_type == 'Transformer':\n",
        "    model = Transformer(n_mfcc=opt.n_mfcc).to(device)\n",
        "else:\n",
        "    raise ValueError(f\"Invalid model type specified: {opt.model_type}\")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqSs6MVMhEl0"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 로딩\n",
        "fold_data = get_kfold_data(root=opt.data_root, n_mfcc=opt.n_mfcc)\n",
        "\n",
        "# K-Fold 설정\n",
        "kf = KFold(n_splits=opt.n_splits, shuffle=True, random_state=opt.random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[136], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 학습 및 검증 루프 시작\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_idx, val_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fold_data):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopt\u001b[38;5;241m.\u001b[39mn_splits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# 학습/검증 데이터로 쪼개기\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "# 학습 및 검증 루프 시작\n",
        "for fold, (train_mfcc, val_mfcc, train_emotion, val_emotion) in enumerate(fold_data):\n",
        "    print(f\"Fold {fold + 1}/{opt.n_splits}\")\n",
        "\n",
        "    model = CNN().to(device)\n",
        "    # 학습/검증 데이터셋 생성\n",
        "    train_set = SegDataset(train_mfcc, train_emotion)\n",
        "    val_set = SegDataset(val_mfcc, val_emotion)\n",
        "\n",
        "    # 데이터 로더 생성 (각 배치 단위로 데이터를 GPU에 올리기)\n",
        "    train_loader = DataLoader(train_set, batch_size=opt.batch_size, shuffle=True, drop_last=True, num_workers=opt.num_workers)\n",
        "    val_loader = DataLoader(val_set, batch_size=opt.batch_size, shuffle=False, drop_last=False, num_workers=opt.num_workers)\n",
        "\n",
        "    # 각 fold에 따라 pos_weight 동적으로 설정\n",
        "    num_pos = sum(em == 1 for em in train_emotion)\n",
        "    num_neg = sum(em == 0 for em in train_emotion)\n",
        "    pos_weight = torch.tensor([num_neg / num_pos]).to(device) if num_pos > 0 else torch.tensor([1.0]).to(device)\n",
        "\n",
        "    # 손실 함수 및 옵티마이저 선언\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr)\n",
        "\n",
        "    # 현재 폴드 값들 저장\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_epoch = 0\n",
        "\n",
        "    # 에포크 루프\n",
        "    for epo in range(opt.epoch):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        # 학습 루프 (각 배치 단위로 데이터를 GPU에 올리기)\n",
        "        for mfcc, emotion in train_loader:\n",
        "            # 데이터를 GPU로 옮기기\n",
        "            mfcc, emotion = mfcc.to(device), emotion.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output_emotion = model(mfcc)\n",
        "\n",
        "            emotion = emotion.float()\n",
        "            loss = criterion(output_emotion[:, 0].squeeze(), emotion)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # 사용 후 메모리에서 해제\n",
        "            del mfcc, emotion, output_emotion\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # 검증 루프\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct_emotion = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for mfcc, emotion in val_loader:\n",
        "                # 데이터를 GPU로 옮기기\n",
        "                mfcc, emotion = mfcc.to(device), emotion.to(device)\n",
        "                output_emotion = model(mfcc)\n",
        "                emotion = emotion.float()\n",
        "\n",
        "                loss = criterion(output_emotion[:, 0].squeeze(), emotion)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted_emotion = (torch.sigmoid(output_emotion[:, 0]) > 0.5).float()\n",
        "                correct_emotion += (predicted_emotion == emotion).sum().item()\n",
        "                total += emotion.size(0)\n",
        "\n",
        "                # 사용 후 메모리에서 해제\n",
        "                del mfcc, emotion, output_emotion\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        # 정확도 계산 시 total이 0인지 확인\n",
        "        val_accuracy = correct_emotion / total if total > 0 else 0.0\n",
        "\n",
        "        print(f\"Fold {fold + 1} | Epoch {epo} | Train Loss: {train_loss / len(train_loader)} | Val Loss: {val_loss / len(val_loader)} | Val Accuracy: {val_accuracy}\")\n",
        "\n",
        "        # 모델 저장\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_epoch = epo\n",
        "            torch.save(model.state_dict(), os.path.join(opt.save_root, f'fold_{fold + 1}_best_epoch.pth'))\n",
        "\n",
        "        # 학습 및 검증 손실 및 정확도 기록\n",
        "        train_losses.append(train_loss / len(train_loader))\n",
        "        val_losses.append(val_loss / len(val_loader))\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Fold {fold + 1} best epoch: {best_epoch}\")\n",
        "\n",
        "    # 각 폴드의 학습 손실, 검증 손실 및 정확도 시각화\n",
        "    plot_fold_performance(train_losses, val_losses, val_accuracies, fold)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
